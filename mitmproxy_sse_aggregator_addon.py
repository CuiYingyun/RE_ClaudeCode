#!/usr/bin/env python3
"""
mitmproxy addon: å®æ—¶èšåˆ SSE å“åº”ä¸­çš„ content_block_delta äº‹ä»¶
ä½¿ç”¨æ–¹æ³•: mitmweb -s sse_aggregator_addon.py
"""

import json
from collections import defaultdict
from mitmproxy import http, ctx
from typing import Dict, List, Any


class SSEAggregator:
    def __init__(self):
        self.aggregated_flows = {}  # å­˜å‚¨èšåˆåçš„æ•°æ®
    
    def response(self, flow: http.HTTPFlow) -> None:
        """å¤„ç†å“åº”"""
        # åªå¤„ç† SSE å“åº”
        content_type = flow.response.headers.get("content-type", "")
        if "text/event-stream" not in content_type and "application/json" not in content_type:
            return
        
        # åªå¤„ç†ç‰¹å®š APIï¼ˆå¯æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
        if not any(domain in flow.request.pretty_url for domain in [
            "api.anthropic.com",
            "api.openai.com",
            "api.moonshot.cn",
            "generativelanguage.googleapis.com"
        ]):
            return
        
        try:
            content = flow.response.content.decode('utf-8', errors='ignore')
            
            # è§£æ SSE äº‹ä»¶
            events = self._parse_sse_content(content)
            if not events:
                return
            
            # èšåˆ content_block_delta
            aggregated_events = self._aggregate_content_deltas(events)
            
            # æ ¼å¼åŒ–èšåˆåçš„å†…å®¹
            aggregated_text = self._format_aggregated_events(aggregated_events)
            
            # æå–å…³é”®å†…å®¹ç”¨äº comment
            summary = self._extract_summary(aggregated_events)
            
            # è®¾ç½® comment æ˜¾ç¤ºèšåˆåçš„å…³é”®ä¿¡æ¯
            flow.comment = f"âœ… SSE ({len(events)}â†’{len(aggregated_events)})\n{summary}"
            
            # ç›´æ¥ä¿®æ”¹å“åº”ä½“ä¸ºèšåˆåçš„å†…å®¹ï¼ˆåœ¨ Response æ ‡ç­¾æŸ¥çœ‹ï¼‰
            flow.response.content = aggregated_text.encode('utf-8')
            
            # åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯
            ctx.log.info("=" * 80)
            ctx.log.info(f"SSE Response Aggregated - {flow.request.method} {flow.request.pretty_url}")
            ctx.log.info("=" * 80)
            ctx.log.info(aggregated_text)
            ctx.log.info("=" * 80)
            
        except Exception as e:
            ctx.log.error(f"SSE aggregation error: {e}")
    
    def _parse_sse_content(self, content: str) -> List[Dict[str, Any]]:
        """è§£æ SSE å†…å®¹"""
        events = []
        current_event = {}
        
        for line in content.split('\n'):
            line = line.rstrip('\r')
            
            if line.startswith('event: '):
                if current_event:
                    events.append(current_event)
                current_event = {'event': line[7:]}
            elif line.startswith('data: '):
                try:
                    current_event['data'] = json.loads(line[6:])
                except json.JSONDecodeError:
                    current_event['data'] = line[6:]
            elif line == '':
                if current_event:
                    events.append(current_event)
                    current_event = {}
        
        if current_event:
            events.append(current_event)
        
        return events
    
    def _aggregate_content_deltas(self, events: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """èšåˆ content_block_delta äº‹ä»¶"""
        result = []
        delta_buffer = defaultdict(lambda: {
            'thinking_delta': [],
            'text_delta': [],
            'input_json_delta': []
        })
        
        for event in events:
            event_type = event.get('event')
            data = event.get('data', {})
            
            if event_type == 'content_block_delta' and isinstance(data, dict):
                index = data.get('index', 0)
                delta = data.get('delta', {})
                delta_type = delta.get('type', '')
                
                # æ”¶é›†ä¸åŒç±»å‹çš„ delta
                if delta_type == 'thinking_delta':
                    delta_buffer[index]['thinking_delta'].append(delta.get('thinking', ''))
                elif delta_type == 'text_delta':
                    delta_buffer[index]['text_delta'].append(delta.get('text', ''))
                elif delta_type == 'input_json_delta':
                    delta_buffer[index]['input_json_delta'].append(delta.get('partial_json', ''))
            else:
                # åœ¨é‡åˆ°é delta äº‹ä»¶å‰ï¼Œå…ˆè¾“å‡ºç¼“å­˜çš„èšåˆå†…å®¹
                if delta_buffer:
                    for index in sorted(delta_buffer.keys()):
                        aggregated = {}
                        
                        if delta_buffer[index]['thinking_delta']:
                            aggregated['thinking_delta'] = ''.join(delta_buffer[index]['thinking_delta'])
                        if delta_buffer[index]['text_delta']:
                            aggregated['text_delta'] = ''.join(delta_buffer[index]['text_delta'])
                        if delta_buffer[index]['input_json_delta']:
                            aggregated['input_json_delta'] = ''.join(delta_buffer[index]['input_json_delta'])
                        
                        if aggregated:
                            result.append({
                                'event': 'content_block_delta (aggregated)',
                                'data': {
                                    'type': 'content_block_delta',
                                    'index': index,
                                    'aggregated_content': aggregated
                                }
                            })
                    
                    delta_buffer.clear()
                
                # æ·»åŠ å½“å‰äº‹ä»¶
                result.append(event)
        
        # å¤„ç†æœ«å°¾å‰©ä½™çš„ delta
        if delta_buffer:
            for index in sorted(delta_buffer.keys()):
                aggregated = {}
                
                if delta_buffer[index]['thinking_delta']:
                    aggregated['thinking_delta'] = ''.join(delta_buffer[index]['thinking_delta'])
                if delta_buffer[index]['text_delta']:
                    aggregated['text_delta'] = ''.join(delta_buffer[index]['text_delta'])
                if delta_buffer[index]['input_json_delta']:
                    aggregated['input_json_delta'] = ''.join(delta_buffer[index]['input_json_delta'])
                
                if aggregated:
                    result.append({
                        'event': 'content_block_delta (aggregated)',
                        'data': {
                            'type': 'content_block_delta',
                            'index': index,
                            'aggregated_content': aggregated
                        }
                    })
        
        return result
    
    def _format_aggregated_events(self, events: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–èšåˆåçš„äº‹ä»¶ä¸ºæ–‡æœ¬"""
        lines = []
        
        for event in events:
            event_name = event.get('event', '')
            data = event.get('data')
            
            lines.append(f"event: {event_name}")
            if isinstance(data, dict):
                lines.append(f"data: {json.dumps(data, ensure_ascii=False, indent=2)}")
            elif data:
                lines.append(f"data: {data}")
            lines.append('')
        
        return '\n'.join(lines)
    
    def _extract_summary(self, events: List[Dict[str, Any]]) -> str:
        """æå–èšåˆäº‹ä»¶çš„æ‘˜è¦ä¿¡æ¯"""
        summary_parts = []
        
        for event in events:
            event_name = event.get('event', '')
            data = event.get('data', {})
            
            if event_name == 'content_block_delta (aggregated)':
                aggregated_content = data.get('aggregated_content', {})
                index = data.get('index', 0)
                
                if 'thinking_delta' in aggregated_content:
                    text = aggregated_content['thinking_delta'][:100]
                    summary_parts.append(f"[{index}] ğŸ’­ {text}...")
                
                if 'text_delta' in aggregated_content:
                    text = aggregated_content['text_delta'][:100]
                    summary_parts.append(f"[{index}] ğŸ“ {text}...")
                
                if 'input_json_delta' in aggregated_content:
                    try:
                        json_obj = json.loads(aggregated_content['input_json_delta'])
                        if 'command' in json_obj:
                            cmd = json_obj['command'][:80]
                            summary_parts.append(f"[{index}] ğŸ”§ {cmd}...")
                    except:
                        pass
        
        return '\n'.join(summary_parts[:3]) if summary_parts else "SSE Aggregated"


addons = [SSEAggregator()]
